# -*- coding: utf-8 -*-
"""p2p.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bAPWD0I14bn8u_zw6MEPfIuoAXCtpsZV
"""

import nltk
import pandas as pd
import numpy as np
import sklearn
import seaborn as sns

df = pd.read_csv("IMDB Dataset.csv")
df

df['sentiment'].replace('positive',1,inplace=True)
df['sentiment'].replace('negative',0,inplace=True)

df

df = df.sample(n=10000, random_state=42)
df

sns.countplot(x='sentiment', data=df)
# plt.title("Sentiment distribution")

import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))

def preprocess(text):
    # Convert text to lowercase
    text = text.lower()

    # Remove <br /> tags
    text = re.sub("<br />", "", text)

    # Remove URLs
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)

    # Remove punctuation
    text = re.sub(r'[^\w\s]', '', text)

    # Tokenize text
    tokens = word_tokenize(text)

    # Filter out stopwords
    filtered_text = [w for w in tokens if not w in stop_words]

    # Initialize the stemmer
    stemmer = PorterStemmer()

    # Apply stemming to the filtered text
    stemmed_text = [stemmer.stem(word) for word in filtered_text]

    # Join the stemmed words into a single string
    return " ".join(stemmed_text)

df['review'] = df['review'].apply(preprocess)

df

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

X = df['review']
Y = df['sentiment']

vect = TfidfVectorizer()
X = vect.fit_transform(df['review'])

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

x_train = x_train.toarray()
x_test = x_test.toarray()

from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(units=16, activation='relu', input_dim=x_train.shape[1]))
model.add(Dense(units=8, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(x_train, y_train, batch_size=10, epochs=4)

# Load the test example
sample_review = "This movie was worst! "


processed_review = preprocess(sample_review)
stemmed_review = stemming(processed_review)

X_test = vect.transform([stemmed_review])

X_test_dense = X_test.toarray()

# Make predictions
prediction = model.predict(X_test_dense)

# Display the prediction
if prediction[0] >= 0.5:
    print("Predicted sentiment: Positive")
else:
    print("Predicted sentiment: Negative")
print("Confidence score:", prediction[0])

